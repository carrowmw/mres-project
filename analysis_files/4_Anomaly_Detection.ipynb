{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run mpl_config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\#code\\#python\\#current\\mres-project\\analysis_files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from modelling_functions import (\n",
    "    LSTMModel,\n",
    "    LinearModel,\n",
    "    prepare_dataloaders,\n",
    "    load_and_preprocess_data,\n",
    "    evaluate_anomalies,\n",
    ")\n",
    "\n",
    "\n",
    "from eda_helper import (\n",
    "    get_custom_palette,\n",
    "    get_custom_heatmap,\n",
    "    get_custom_colormap,\n",
    "    extract_values_from_filename,\n",
    ")\n",
    "\n",
    "custom_palette = get_custom_palette()\n",
    "custom_heatmap = get_custom_heatmap()\n",
    "custom_colormap = get_custom_colormap()\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "column_names = [\n",
    "    \"MAE\",\n",
    "    \"MSE\",\n",
    "    \"RMSE\",\n",
    "    \"R^2\",\n",
    "    \"Model\",\n",
    "    \"Training Time (s)\",\n",
    "    \"Test Number\",\n",
    "    \"Completeness\",\n",
    "    \"Sequence Length\",\n",
    "    \"WindowSize\",\n",
    "    \"Horizon\",\n",
    "]\n",
    "performance = pd.read_csv(\n",
    "    cwd + \"\\\\performance_metrics_mm.csv\", header=None, names=column_names\n",
    ")\n",
    "runtime = pd.read_csv(cwd + \"\\\\runtime_metrics_mm.csv\")\n",
    "weights = pd.read_csv(cwd + \"\\\\weights_mm.csv\")\n",
    "\n",
    "selected_columns = [\n",
    "    \"MAE\",\n",
    "    \"MSE\",\n",
    "    \"RMSE\",\n",
    "    \"R^2\",\n",
    "    \"Training Time (s)\",\n",
    "    \"Test Number\",\n",
    "    \"Completeness\",\n",
    "    \"Sequence Length\",\n",
    "    \"WindowSize\",\n",
    "    \"Horizon\",\n",
    "]\n",
    "\n",
    "performance_lstm = performance[performance[\"Model\"] == \"LSTM\"][selected_columns]\n",
    "performance_linear = performance[performance[\"Model\"] == \"Linear\"][selected_columns]\n",
    "\n",
    "\n",
    "def process_data(dataframe):\n",
    "    \"\"\"\n",
    "    Process the given dataframe based on the provided steps.\n",
    "    Args:\n",
    "    - dataframe (pd.DataFrame): The dataframe to process.\n",
    "    Returns:\n",
    "    - pd.DataFrame: The processed dataframe.\n",
    "    \"\"\"\n",
    "    dataframe = dataframe.sort_values(by=\"R^2\").reset_index(drop=True)\n",
    "    grouped_dataframe = dataframe.groupby(\n",
    "        [\"Completeness\", \"Horizon\", \"WindowSize\"]\n",
    "    ).mean()\n",
    "    grouped_dataframe.reset_index(inplace=True)\n",
    "    sorted_dataframe = grouped_dataframe.sort_values(\n",
    "        by=\"Training Time (s)\"\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return sorted_dataframe\n",
    "\n",
    "\n",
    "# Process the dataframes\n",
    "sorted_lstm_performance = process_data(performance_lstm)\n",
    "sorted_linear_performance = process_data(performance_linear)\n",
    "\n",
    "# Multiplying index value by length of window_sizes to get the correct index for viewing\n",
    "sorted_linear_performance.index = sorted_lstm_performance.iloc[::6].index\n",
    "\n",
    "window_values = np.sort(sorted_lstm_performance[\"WindowSize\"].unique())\n",
    "horizon_values = np.sort(sorted_lstm_performance[\"Horizon\"].unique())\n",
    "completeness_values = np.sort(sorted_lstm_performance[\"Completeness\"].unique())\n",
    "\n",
    "# Additional operations for linear_data\n",
    "sorted_linear_performance = sorted_linear_performance.sort_values(\n",
    "    [\"Completeness\", \"Horizon\"], ascending=[False, True]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extracts the Completeness, Sequence Length, Horizon, and Window Size values\n",
    "    from the given filename using regular expressions.\n",
    "\n",
    "    Args:\n",
    "    - filename (str): The filename to extract the values from.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the extracted values. Returns None for values not found.\n",
    "    \"\"\"\n",
    "    # Regular expressions for each value\n",
    "    regex_patterns = {\n",
    "        \"Completeness\": r\"Completeness([\\d.]+)\",\n",
    "        \"SequenceLength\": r\"SequenceLength(\\d+)\",\n",
    "        \"Horizon\": r\"Horizon(\\d+)\",\n",
    "        \"WindowSize\": r\"WindowSize(\\d+)\",\n",
    "        \"TestNumber\": r\"TestNumber(\\d+)\",\n",
    "    }\n",
    "\n",
    "    extracted_values = {}\n",
    "    for key, pattern in regex_patterns.items():\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            # Convert to float if it has a decimal point, else convert to int\n",
    "            value = (\n",
    "                float(match.group(1)) if \".\" in match.group(1) else int(match.group(1))\n",
    "            )\n",
    "            extracted_values[key] = value\n",
    "        else:\n",
    "            extracted_values[key] = None\n",
    "\n",
    "    return extracted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"440\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#4060af;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ff5416;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#fdc82f;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#00b2a9;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#e7e6e6;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#93509e;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"330\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#00a9e0;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"385\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#cf0071;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.25098039215686274, 0.3764705882352941, 0.6862745098039216),\n",
       " (1.0, 0.32941176470588235, 0.08627450980392157),\n",
       " (0.9921568627450981, 0.7843137254901961, 0.1843137254901961),\n",
       " (0.0, 0.6980392156862745, 0.6627450980392157),\n",
       " (0.9058823529411765, 0.9019607843137255, 0.9019607843137255),\n",
       " (0.5764705882352941, 0.3137254901960784, 0.6196078431372549),\n",
       " (0.0, 0.6627450980392157, 0.8784313725490196),\n",
       " (0.8117647058823529, 0.0, 0.44313725490196076)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing incomplete days...\n",
      "Initial number of records: 39904\n",
      "Number of records in days @ 50% completeness: 39072\n",
      "Proportion of records removed: 2.09%\n",
      "Maximum consecutive days: 89\n",
      "Starting from day number 1 in 2023\n"
     ]
    }
   ],
   "source": [
    "# Assuming custom_palette is predefined\n",
    "custom_palette = get_custom_palette()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define paths\n",
    "model_folder_path = (\n",
    "    r\"C:\\#code\\#python\\#current\\mres-project\\analysis_files\\mv_model_states\"\n",
    ")\n",
    "graph_save_path = (\n",
    "    r\"C:\\#code\\#python\\#current\\mres-project\\analysis_files\\mv_anomaly_graphs\"\n",
    ")\n",
    "results_save_path = r\"C:\\#code\\#python\\#current\\mres-project\\analysis_files\\mv_results\"\n",
    "os.makedirs(graph_save_path, exist_ok=True)\n",
    "os.makedirs(results_save_path, exist_ok=True)\n",
    "\n",
    "# Empty dataframe to store the results\n",
    "results_list = []\n",
    "\n",
    "input_feature_indices = list(range(0, 11))\n",
    "target_feature_index = 0\n",
    "stride = 1\n",
    "\n",
    "completeness_value = 0.5\n",
    "east_timeseries = load_and_preprocess_data(completeness_value)\n",
    "data = east_timeseries\n",
    "\n",
    "num_runs = 5  # Change to the desired number of runs\n",
    "\n",
    "for model_file in os.listdir(model_folder_path):\n",
    "    # Ensure it's a .pt file (PyTorch model state file)\n",
    "    if not model_file.endswith(\".pt\"):\n",
    "        continue\n",
    "\n",
    "    # Create placeholders for metrics\n",
    "    mean_errors_runs = []\n",
    "    anomaly_percentages_runs = []\n",
    "    anomaly_thresholds_runs = []\n",
    "    rmse_runs = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        # Extract values from filename\n",
    "        values = extract_values_from_filename(model_file)\n",
    "        sequence_length_value = values[\"SequenceLength\"]\n",
    "        horizon_value = values[\"Horizon\"]\n",
    "        window_size_value = values[\"WindowSize\"]\n",
    "        model_completeness_value = values[\"Completeness\"]\n",
    "        test_number = values[\"TestNumber\"]\n",
    "        # Load and preprocess data if completeness value changes\n",
    "\n",
    "        print()\n",
    "        print(\"Overview of  Dataloader Parameters for Testing\")\n",
    "        print(\n",
    "            f\"Sequence Length: {sequence_length_value} | Horizon: {horizon_value} | Window Size: {window_size_value} | Completeness: {completeness_value}\"\n",
    "        )\n",
    "\n",
    "        (\n",
    "            train_dataLoader,\n",
    "            test_dataloader,\n",
    "            test_inputs,\n",
    "            test_targets,\n",
    "            train_inputs,\n",
    "            train_targets,\n",
    "        ) = prepare_dataloaders(\n",
    "            data=data,\n",
    "            window_size=window_size_value,\n",
    "            input_feature_indices=input_feature_indices,\n",
    "            target_feature_index=target_feature_index,\n",
    "            horizon=horizon_value,\n",
    "            stride=stride,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        print(f\"Length of test_inputs: {len(test_inputs)}\")\n",
    "\n",
    "        # Load model state\n",
    "        state_path = os.path.join(model_folder_path, model_file)\n",
    "        if model_file.startswith(\"Linear\"):\n",
    "            model = LinearModel(input_size=len(input_feature_indices))\n",
    "            model.load_state_dict(torch.load(state_path))\n",
    "            model.to(device)\n",
    "        else:\n",
    "            model = LSTMModel(feature_dim=len(input_feature_indices))\n",
    "            model.load_state_dict(torch.load(state_path))\n",
    "            model.to(device)\n",
    "\n",
    "        print(\n",
    "            f\"Test inputs dtype: {test_inputs.dtype}, Test targets dtype: {test_targets.dtype}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Test inputs type: {type(test_inputs)}, Test targets type: {type(test_targets)}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Test inputs shape: {test_inputs.shape}, Test targets shape: {test_targets.shape}\"\n",
    "        )\n",
    "        with torch.inference_mode():\n",
    "            train_inputs = train_inputs.float()\n",
    "            predictions = model(train_inputs).squeeze().numpy()\n",
    "            targets = train_targets.numpy()\n",
    "            inputs = train_inputs.numpy()\n",
    "        print(\n",
    "            f\"Predictions shape: {predictions.shape}, Inputs shape: {inputs.shape}, Targets shape: {targets.shape}\"\n",
    "        )\n",
    "\n",
    "        errors = np.abs(predictions - targets)\n",
    "        # Calculating the RMSE\n",
    "        rmse = np.sqrt(np.mean(errors**2))\n",
    "        totals = []\n",
    "        percentages = []\n",
    "        standard_deviations = list(np.arange(start=2, stop=10.01, step=0.1))\n",
    "\n",
    "        for i in standard_deviations:\n",
    "            threshold_i = errors.mean() + i * errors.std()\n",
    "            anomalies_i = errors > threshold_i\n",
    "            total_anomalies_i = np.sum(anomalies_i)\n",
    "            anomaly_percentage_i = total_anomalies_i / len(targets)\n",
    "            totals.append(total_anomalies_i)\n",
    "            percentages.append(anomaly_percentage_i)\n",
    "\n",
    "        # Set anomaly threshold\n",
    "        error_deviations = 6\n",
    "        percentages = [\n",
    "            p * 100 for p in percentages\n",
    "        ]  # Multiply by 100 to get percentage\n",
    "        # Plotting the first graph\n",
    "        fig, ax = plt.subplots(figsize=(7, 7))\n",
    "        ax.set_title(\n",
    "            f\" Model number {test_number} \\n Training metrics | Completeness threshold {model_completeness_value*100}% | Sequence length: {sequence_length_value} \\n Evaluation metrics | Completenesss threshold: {completeness_value * 100}% | Error deviations: {error_deviations} \\n Shared metrics | Horizon: {horizon_value} | Window size: {window_size_value} \\n Results | Mean error: {errors.mean():.2f} | RMSE: {rmse:.2f} | Percentage anomalies: {(total_anomalies/sequence_length_value*100):.1f}% | Anomaly threshold: {anomaly_threshold}$\\sigma$\",\n",
    "            fontsize=14,\n",
    "        )\n",
    "        ax.plot(standard_deviations, percentages, color=custom_palette[6], linewidth=1)\n",
    "        ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        ax.set_xlabel(\"Standard deviations from mean error ($\\sigma$)\")\n",
    "        ax.set_ylabel(\"Anomaly percentage (%) - of total data points\")\n",
    "        ax.set_ylim(0, 7)\n",
    "        # Round the y-axis tick labels to 2 decimal places\n",
    "        ax.set_yticks(ax.get_yticks())\n",
    "\n",
    "        fig.savefig(\n",
    "            os.path.join(graph_save_path, f\"{model_file.split('.p')[0]}_graph1.png\")\n",
    "        )\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Plotting the second graph\n",
    "        errors = np.abs(predictions - targets)\n",
    "\n",
    "        anomaly_threshold = np.round(errors.mean() + error_deviations * errors.std(), 1)\n",
    "        anomalies = errors > anomaly_threshold\n",
    "\n",
    "        # Count total anomalies\n",
    "        total_anomalies = np.sum(anomalies)\n",
    "\n",
    "        anomaly_percentage = (total_anomalies / len(targets)) * 100\n",
    "\n",
    "        # Create time vector\n",
    "        time = np.arange(len(train_inputs))\n",
    "\n",
    "        # Find the indices of all anomalies\n",
    "        anomaly_indices = np.where(anomalies)[0]\n",
    "\n",
    "        # Define t1 and t2\n",
    "        t1, t2 = 300, 600\n",
    "\n",
    "        # Filter those indices to only consider the [t1:t2] range\n",
    "        filtered_anomaly_indices = anomaly_indices[\n",
    "            (anomaly_indices >= t1) & (anomaly_indices < t2)\n",
    "        ]\n",
    "\n",
    "        # Use these filtered indices to get the anomaly_times and anomaly_values\n",
    "        anomaly_times = time[filtered_anomaly_indices]\n",
    "        anomaly_values = targets[filtered_anomaly_indices]\n",
    "\n",
    "        print()\n",
    "        print(\n",
    "            f\"Model number: {test_number} \\n TRAINING METRICS | Completeness threshold {model_completeness_value*100}% | Sequence length: {sequence_length_value} | Model number {test_number} \\n EVALUATION METRICS | Completenesss threshold: {completeness_value * 100}% | SHARED METRICS | Horizon: {horizon_value} | Window size: {window_size_value} \\n Anomalies: {anomalies.shape} | Time: {time.shape} | Errors: {errors.shape} | Threshold: {threshold_i.shape} |Targets: {targets.shape} | Predictions: {predictions.shape}\",\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 9))\n",
    "        # Plot the time series\n",
    "        ax.plot(\n",
    "            time[t1:t2],\n",
    "            targets[t1:t2],\n",
    "            label=\"Targets\",\n",
    "            linewidth=1,\n",
    "            color=custom_palette[0],\n",
    "        )\n",
    "        ax.plot(\n",
    "            time[t1:t2],\n",
    "            predictions[t1:t2],\n",
    "            linewidth=1,\n",
    "            label=\"Predicted data\",\n",
    "            color=custom_palette[1],\n",
    "        )\n",
    "\n",
    "        # Mark the anomalies\n",
    "        ax.scatter(\n",
    "            anomaly_times,\n",
    "            anomaly_values,\n",
    "            label=\"Anomalies\",\n",
    "            color=custom_palette[7],\n",
    "            marker=\"x\",\n",
    "            s=60,\n",
    "            zorder=3,\n",
    "        )\n",
    "        ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "        ax.set_ylim(-1, 3)\n",
    "        ax.set_ylabel(\"Scaled value\")\n",
    "        ax.set_xlabel(\"Timestep\")\n",
    "        ax.set_title(\n",
    "            f\" Model number {test_number} \\n Training metrics | Completeness threshold {model_completeness_value*100}% | Sequence length: {sequence_length_value} \\n Evaluation metrics | Completenesss threshold: {completeness_value * 100}% | Error deviations: {error_deviations} \\n Shared metrics | Horizon: {horizon_value} | Window size: {window_size_value} \\n Results | Mean error: {errors.mean():.2f} | Percentage anomalies: {(total_anomalies/sequence_length_value*100):.1f}% | Anomaly threshold: {anomaly_threshold}$\\sigma$\",\n",
    "            fontsize=14,\n",
    "        )\n",
    "        ax.legend(loc=\"upper right\")\n",
    "        fig.savefig(\n",
    "            os.path.join(graph_save_path, f\"{model_file.split('.p')[0]}_graph2.png\")\n",
    "        )\n",
    "        plt.close(fig)\n",
    "\n",
    "        # After computing necessary metrics:\n",
    "        mean_errors_runs.append(errors.mean())\n",
    "        rmse_runs.append(rmse)\n",
    "        anomaly_percentages_runs.append(anomaly_percentage)\n",
    "        anomaly_thresholds_runs.append(anomaly_threshold)\n",
    "\n",
    "    # After all runs for a model, compute average metrics\n",
    "    avg_mae = np.mean(mean_errors_runs)\n",
    "    avg_rmse = np.mean(rmse_runs)\n",
    "    avg_anomaly_percentage = np.mean(anomaly_percentages_runs)\n",
    "    avg_anomaly_threshold = np.mean(anomaly_thresholds_runs)\n",
    "\n",
    "    # Store the average evaluation results in the results_list\n",
    "    results_list.append(\n",
    "        {\n",
    "            \"Model\": model_file,\n",
    "            \"MAE\": avg_mae,\n",
    "            \"RMSE\": avg_rmse,\n",
    "            \"Anomaly Percentage\": avg_anomaly_percentage,\n",
    "            \"Anomaly Threshold\": avg_anomaly_threshold,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# After the loop, create the dataframe\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "results_df.to_csv(\n",
    "    os.path.join(\n",
    "        results_save_path,\n",
    "        f\"features{len(input_feature_indices)}_completeness{completeness_value}_ed{error_deviations}_runs{num_runs}_evaluation_results.csv\",\n",
    "    ),\n",
    "    index=False,\n",
    "    mode=\"w\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
