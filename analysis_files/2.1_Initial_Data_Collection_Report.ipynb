{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Data Collection Report\n",
    "\n",
    "In this section, we will describe the initial collection of data. This includes:\n",
    "\n",
    "* Description of the data sources used: where the data was obtained from, how it was collected, and by whom.\n",
    "* The methods used to gather the data: for example, were the data collected through surveys, web scraping, APIs, or was it accessed directly from a database?\n",
    "* Any difficulties or issues that came up during data collection: problems with data availability, issues with access to data sources, or other technical difficulties."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Description of the Data Sources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 CSV data from the Urban Observatory\n",
    "\n",
    "The raw data in this section was collated by Tom Komar from the Urban Observatory as an initial test dataset for this project. \n",
    "\n",
    "Here we will adapt and filter the data to suit the purposes of this project:\n",
    "\n",
    "* Read data into a dataframe.\n",
    "* Setting datatypes for dataframe columns.\n",
    "* Addition of various time units to aid data exploration.\n",
    "* Isolate a single point location for data exploration (this is the intersection of Northumberland Street and Saville Row with cameras looking both east and west)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize\n",
    "\n",
    "# path to data files\n",
    "RAW_DATA_PATH = './data/tom_komar_csv_22_23/'\n",
    "\n",
    "# dictionary to store dataframes\n",
    "dfs = {}\n",
    "\n",
    "# iterating over all files in the directory\n",
    "for file in os.listdir(RAW_DATA_PATH):\n",
    "    # reading file into a dataframe\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_PATH, file))\n",
    "    # extracting date from the filename\n",
    "    date = '-'.join(re.split(r\"[-.]\", file)[-3:-1])\n",
    "    # storing dataframe in the dictionary with date as the key\n",
    "    dfs[date] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all dataframes into a single dataframe\n",
    "concat_df = pd.concat([df.assign(key=key) for key, df in dfs.items()])\n",
    "\n",
    "# filtering data for specific locations\n",
    "concat_df = concat_df[concat_df['location'].isin(['NclNorthumberlandStSavilleRowEast', 'NclNorthumberlandStSavilleRowWest'])]\n",
    "\n",
    "# splitting 'dt' column into 'date' and 'time' columns\n",
    "concat_df[['date', 'time']] = concat_df['dt'].str.split(' ', expand=True)\n",
    "\n",
    "# converting 'dt', 'date', 'time' columns to datetime format\n",
    "concat_df['dt'] = pd.to_datetime(concat_df['dt'])\n",
    "concat_df['date'] = pd.to_datetime(concat_df['date'])\n",
    "concat_df['time'] = pd.to_datetime(concat_df['time'], format='%H:%M:%S').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting various time units from 'dt' column\n",
    "concat_df['year-month-day-hour'] = concat_df['dt'].dt.strftime('%Y-%m-%d %H')\n",
    "concat_df['year-month-hour'] = concat_df['dt'].dt.strftime('%Y-%m %H')\n",
    "concat_df['month-hour'] = concat_df['dt'].dt.strftime('%m %H')\n",
    "concat_df['hour'] = concat_df['dt'].dt.hour\n",
    "concat_df['month'] = concat_df['date'].dt.month\n",
    "concat_df['quarter'] = concat_df['date'].dt.quarter\n",
    "concat_df['year-month'] = concat_df['dt'].dt.strftime('%Y-%m')\n",
    "concat_df['year-week'] = concat_df['date'].dt.strftime('%Y-%U')\n",
    "concat_df['year-quarter'] = concat_df['dt'].apply(lambda x: f\"{x.year}-{(x.month - 1) // 3 + 1}\")\n",
    "concat_df['day_of_week'] = concat_df['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing data into east and west dataframes\n",
    "east_df = concat_df[concat_df['location'] == 'NclNorthumberlandStSavilleRowEast']\n",
    "west_df = concat_df[concat_df['location'] == 'NclNorthumberlandStSavilleRowWest']\n",
    "\n",
    "DATA_PATH = './data/saville_row_east_west/'\n",
    "\n",
    "# east_df.to_csv(os.path.join(DATA_PATH,'east_df.csv'))\n",
    "# west_df.to_csv(os.path.join(DATA_PATH, 'west_df.csv'))\n",
    "\n",
    "east_df.to_pickle(os.path.join(DATA_PATH, 'east_df.pkl'))\n",
    "west_df.to_pickle(os.path.join(DATA_PATH, 'west_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
